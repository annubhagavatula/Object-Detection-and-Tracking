{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef96fb9-5f88-4198-9759-293740d04094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available sequence folders: ['uav0000013_00000_v', 'uav0000013_01073_v', 'uav0000013_01392_v', 'uav0000020_00406_v', 'uav0000071_03240_v', 'uav0000072_04488_v', 'uav0000072_05448_v', 'uav0000072_06432_v', 'uav0000076_00720_v', 'uav0000079_00480_v', 'uav0000084_00000_v', 'uav0000099_02109_v', 'uav0000124_00944_v', 'uav0000126_00001_v', 'uav0000138_00000_v', 'uav0000140_01590_v', 'uav0000143_02250_v', 'uav0000145_00000_v', 'uav0000150_02310_v', 'uav0000218_00001_v', 'uav0000222_03150_v', 'uav0000239_03720_v', 'uav0000239_12336_v', 'uav0000243_00001_v', 'uav0000244_01440_v', 'uav0000248_00001_v', 'uav0000263_03289_v', 'uav0000264_02760_v', 'uav0000266_03598_v', 'uav0000266_04830_v', 'uav0000270_00001_v', 'uav0000273_00001_v', 'uav0000278_00001_v', 'uav0000279_00001_v', 'uav0000281_00460_v', 'uav0000288_00001_v', 'uav0000289_00001_v', 'uav0000289_06922_v', 'uav0000295_02300_v', 'uav0000300_00000_v', 'uav0000307_00000_v', 'uav0000308_00000_v', 'uav0000308_01380_v', 'uav0000309_00000_v', 'uav0000315_00000_v', 'uav0000316_01288_v', 'uav0000323_01173_v', 'uav0000326_01035_v', 'uav0000329_04715_v', 'uav0000342_04692_v', 'uav0000352_05980_v', 'uav0000357_00920_v', 'uav0000360_00001_v', 'uav0000361_02323_v', 'uav0000363_00001_v', 'uav0000366_00001_v']\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 2 trucks, 232.2ms\n",
      "Speed: 8.4ms preprocess, 232.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 4 trucks, 203.7ms\n",
      "Speed: 3.2ms preprocess, 203.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 3 trucks, 171.1ms\n",
      "Speed: 3.1ms preprocess, 171.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 2 trucks, 207.5ms\n",
      "Speed: 4.2ms preprocess, 207.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 1 bus, 3 trucks, 190.0ms\n",
      "Speed: 3.5ms preprocess, 190.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 2 trucks, 91.3ms\n",
      "Speed: 1.8ms preprocess, 91.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 1 bus, 119.4ms\n",
      "Speed: 2.3ms preprocess, 119.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 1 truck, 120.2ms\n",
      "Speed: 3.4ms preprocess, 120.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 1 bus, 1 truck, 125.0ms\n",
      "Speed: 2.3ms preprocess, 125.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 1 truck, 84.3ms\n",
      "Speed: 2.5ms preprocess, 84.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 1 bus, 2 trucks, 145.7ms\n",
      "Speed: 2.5ms preprocess, 145.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 17 cars, 1 bus, 161.1ms\n",
      "Speed: 4.0ms preprocess, 161.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 cars, 1 bus, 1 truck, 145.0ms\n",
      "Speed: 2.5ms preprocess, 145.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 141.1ms\n",
      "Speed: 2.5ms preprocess, 141.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 cars, 1 bus, 92.2ms\n",
      "Speed: 2.3ms preprocess, 92.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 3 trucks, 121.9ms\n",
      "Speed: 2.4ms preprocess, 121.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 cars, 1 bus, 3 trucks, 115.0ms\n",
      "Speed: 2.6ms preprocess, 115.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 1 bus, 2 trucks, 104.8ms\n",
      "Speed: 2.5ms preprocess, 104.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 2 trucks, 113.5ms\n",
      "Speed: 3.6ms preprocess, 113.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 1 bus, 1 truck, 145.5ms\n",
      "Speed: 2.0ms preprocess, 145.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 12 cars, 1 bus, 2 trucks, 103.3ms\n",
      "Speed: 2.1ms preprocess, 103.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 11 cars, 1 bus, 2 trucks, 125.7ms\n",
      "Speed: 2.3ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 2 trucks, 123.6ms\n",
      "Speed: 2.0ms preprocess, 123.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 1 bus, 1 truck, 155.6ms\n",
      "Speed: 3.3ms preprocess, 155.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 128.4ms\n",
      "Speed: 2.2ms preprocess, 128.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 1 bus, 131.0ms\n",
      "Speed: 1.9ms preprocess, 131.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 93.4ms\n",
      "Speed: 1.9ms preprocess, 93.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 19 cars, 1 bus, 99.3ms\n",
      "Speed: 5.1ms preprocess, 99.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 1 bus, 2 trucks, 150.8ms\n",
      "Speed: 2.1ms preprocess, 150.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 13 cars, 2 buss, 135.7ms\n",
      "Speed: 2.9ms preprocess, 135.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 1 truck, 156.0ms\n",
      "Speed: 4.8ms preprocess, 156.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 18 cars, 2 buss, 1 truck, 137.2ms\n",
      "Speed: 2.4ms preprocess, 137.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 17 cars, 2 buss, 139.8ms\n",
      "Speed: 2.3ms preprocess, 139.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 1 bus, 150.0ms\n",
      "Speed: 2.4ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 1 truck, 160.9ms\n",
      "Speed: 3.5ms preprocess, 160.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 3 trucks, 106.0ms\n",
      "Speed: 2.3ms preprocess, 106.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 1 truck, 101.7ms\n",
      "Speed: 2.6ms preprocess, 101.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 20 cars, 1 bus, 2 trucks, 115.9ms\n",
      "Speed: 2.0ms preprocess, 115.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 12 cars, 1 bus, 3 trucks, 107.4ms\n",
      "Speed: 2.3ms preprocess, 107.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 16 cars, 1 bus, 2 trucks, 117.6ms\n",
      "Speed: 3.7ms preprocess, 117.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 1 bus, 3 trucks, 108.0ms\n",
      "Speed: 2.2ms preprocess, 108.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 2 trucks, 122.2ms\n",
      "Speed: 1.8ms preprocess, 122.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 1 bus, 3 trucks, 118.8ms\n",
      "Speed: 2.5ms preprocess, 118.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 2 trucks, 116.1ms\n",
      "Speed: 1.9ms preprocess, 116.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 2 buss, 1 truck, 132.0ms\n",
      "Speed: 2.7ms preprocess, 132.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 1 bus, 2 trucks, 92.4ms\n",
      "Speed: 3.2ms preprocess, 92.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 16 cars, 2 buss, 115.8ms\n",
      "Speed: 2.1ms preprocess, 115.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 14 cars, 2 buss, 87.2ms\n",
      "Speed: 2.2ms preprocess, 87.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 14 cars, 2 buss, 1 truck, 116.5ms\n",
      "Speed: 1.9ms preprocess, 116.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 15 cars, 2 buss, 2 trucks, 220.7ms\n",
      "Speed: 4.4ms preprocess, 220.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 buss, 1 truck, 108.9ms\n",
      "Speed: 3.2ms preprocess, 108.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 cars, 2 buss, 2 trucks, 96.8ms\n",
      "Speed: 3.1ms preprocess, 96.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 buss, 1 truck, 90.8ms\n",
      "Speed: 3.8ms preprocess, 90.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 1 truck, 125.0ms\n",
      "Speed: 4.0ms preprocess, 125.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 2 buss, 1 truck, 132.3ms\n",
      "Speed: 3.3ms preprocess, 132.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 2 buss, 1 truck, 334.0ms\n",
      "Speed: 5.7ms preprocess, 334.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 2 buss, 1 truck, 307.2ms\n",
      "Speed: 5.4ms preprocess, 307.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 cars, 2 buss, 1 truck, 431.4ms\n",
      "Speed: 5.8ms preprocess, 431.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 cars, 3 buss, 1 truck, 450.1ms\n",
      "Speed: 5.4ms preprocess, 450.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")  # You can use 'yolov8s.pt' or 'yolov8m.pt' for better accuracy\n",
    "\n",
    "# Define base paths\n",
    "base_path = r\"C:\\Users\\ANNAPURNA\\ANNU\\ML PROJECTS\\VisDrone2019-VID-train\"\n",
    "sequences_path = os.path.join(base_path, \"sequences\")\n",
    "annotations_path = os.path.join(base_path, \"annotations\")\n",
    "\n",
    "# Get all available sequence folders\n",
    "sequence_folders = sorted(os.listdir(sequences_path))\n",
    "print(\"Available sequence folders:\", sequence_folders)\n",
    "\n",
    "if not sequence_folders:\n",
    "    raise FileNotFoundError(\"No sequence folders found in the given path.\")\n",
    "\n",
    "# Pick the first sequence folder\n",
    "first_sequence_folder = sequence_folders[20]\n",
    "first_sequence = os.path.join(sequences_path, first_sequence_folder)\n",
    "first_annotation = os.path.join(annotations_path, first_sequence_folder + \".txt\")\n",
    "\n",
    "# Function to read annotation file\n",
    "def read_annotation(annotation_file):\n",
    "    annotations = {}\n",
    "    if not os.path.exists(annotation_file):\n",
    "        print(f\"Annotation file '{annotation_file}' not found.\")\n",
    "        return annotations\n",
    "\n",
    "    with open(annotation_file, \"r\") as file:\n",
    "        for line in file:\n",
    "            values = line.strip().split(',')\n",
    "            if len(values) < 8:\n",
    "                continue  # Skip malformed lines\n",
    "            frame_id = int(values[0])\n",
    "            obj_id = int(values[1])\n",
    "            x, y, w, h = map(int, values[2:6])\n",
    "            class_id = int(values[7])\n",
    "            if frame_id not in annotations:\n",
    "                annotations[frame_id] = []\n",
    "            annotations[frame_id].append((obj_id, x, y, w, h, class_id))\n",
    "    return annotations\n",
    "\n",
    "# Function to process video sequence\n",
    "def process_sequence(sequence_folder, annotation_file):\n",
    "    images = sorted(os.listdir(sequence_folder))\n",
    "    annotations = read_annotation(annotation_file)\n",
    "\n",
    "    # Prepare for video saving\n",
    "    first_img_path = os.path.join(sequence_folder, images[0])\n",
    "    first_img = cv2.imread(first_img_path)\n",
    "    height, width = first_img.shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(\"output_detection.mp4\", fourcc, 20.0, (width, height))\n",
    "\n",
    "    for img_name in images:\n",
    "        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        frame_id = int(os.path.splitext(img_name)[0])\n",
    "        img_path = os.path.join(sequence_folder, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img is None:\n",
    "            print(f\"Warning: Could not load image {img_path}\")\n",
    "            continue\n",
    "\n",
    "        # Run YOLO detection\n",
    "        results = model(img)\n",
    "\n",
    "        # Iterate over each result (detected object)\n",
    "        for result in results:\n",
    "            for box, cls in zip(result.boxes.xyxy, result.boxes.cls):\n",
    "                x1, y1, x2, y2 = map(int, box[:4])\n",
    "\n",
    "                # Assign labels: \"person\" if class_id == 0, otherwise \"vehicle\"\n",
    "                label = \"person\" if int(cls) == 0 else \"vehicle\"\n",
    "                \n",
    "                # Draw rectangle and label\n",
    "                color = (0, 255, 0) if label == \"person\" else (255, 0, 0)\n",
    "                cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(img, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "\n",
    "        # Draw ground truth annotations (blue)\n",
    "        if frame_id in annotations:\n",
    "            for obj in annotations[frame_id]:\n",
    "                obj_id, x, y, w, h, class_id = obj\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                cv2.putText(img, f\"GT-ID:{obj_id}\", (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "        # Show frame\n",
    "        cv2.imshow(\"Detection\", img)\n",
    "        out.write(img)\n",
    "\n",
    "        # Exit on 'q'\n",
    "        if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Video saved as output_detection.mp4\")\n",
    "\n",
    "# Run on the first sequence\n",
    "process_sequence(first_sequence, first_annotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9816058-1061-4eb4-a605-656de0ee86be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
